[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi I’m Jonathan",
    "section": "",
    "text": "Welcome to this conglomerate of things I’ve worked on.\nAt the moment I’m finishing the last remaining projects for my MPH in Public Health Data Science at the University of Minnesota’s School of Public Health, in the division of Biostatistics and Health Data Science. I also currently work as a research assistant for the Center for Public Health Systems (CPHS) working to develop an ETL pipeline for federal spending data specific to public health. Prior to my masters I finished undergrad at the University of St. Thomas completing a BS in Data Analytics with a Biology domain, and adding minors in Biology and Applied Statistics. During that time I worked full-time, initially for Target over the pandemic, and then for Information and Technology Services (ITS) in support services at the university.\nMy interest in health sciences began as a child where I often found myself entertained with the intricacies of the human body and how it works together. While in high school I was able to be part of the biomedical sciences program at Coon Rapids for four years and additionally I was the first student to participate in both the biomedical and engineering programs. During that time I further developed a love for the quantitative side of health and then following my required semester of statistics in undergrad I officially made the switch from Biology to Data Analytics, with a domain area of Biological Sciences. This allowed me to further develop and apply my abilities with coding and numbers to topics I love in Biology, Public Health, and general Health Sciences.\nBesides my current position, current projects include introductory statistics modules for Public Health Students to be completed prior to taking biostatistics, and developing an online shiny application to assist secondary school students in performing analysis based on collected data."
  },
  {
    "objectID": "Sections/ReferenceGuides/index.html",
    "href": "Sections/ReferenceGuides/index.html",
    "title": "RefernceGuides",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMay 4, 2024\n\n\nBiostat Reference Sheet\n\n\nJonathan Barnes\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/TDTPython.html",
    "href": "Sections/Portfolio/PortProjects/TDTPython.html",
    "title": "Tech Desk Tools",
    "section": "",
    "text": "Tech Desk Tools Python was made to build on the legacy and functionality of the older Tech Desk Tools. The original tech desk tools was created by a Tech Desk student named Jared Klassen around 2019. He wrote in scripts and features that were commonly used or that could be useful for the Tech Desk, the older version combined these into a single application for easier use. The old program functioned fine and did it’s role, however, it was written in AutoHotKey (AHK) which has some limitations when you may want to build or expand functionality and accessibility. It is for that reason we chose to switch it to python in December 2022. Python is easier to read but also allows for more options in its function. This new version was designed to consistently be on your screen and to be useful in many different situations. The application itself does not enable anything special you couldn’t do on your own, but instead works to make it easier to accomplish these tasks.\nTech Desk Tools is designed specifically to be used at the University of St. Thomas and operates behind the scenes using things we have and maintain on campus. For that reason should you try to run this at another university or off campus the application will lock away a lot of functionality."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/TDTPython.html#some-quick-background",
    "href": "Sections/Portfolio/PortProjects/TDTPython.html#some-quick-background",
    "title": "Tech Desk Tools",
    "section": "",
    "text": "Tech Desk Tools Python was made to build on the legacy and functionality of the older Tech Desk Tools. The original tech desk tools was created by a Tech Desk student named Jared Klassen around 2019. He wrote in scripts and features that were commonly used or that could be useful for the Tech Desk, the older version combined these into a single application for easier use. The old program functioned fine and did it’s role, however, it was written in AutoHotKey (AHK) which has some limitations when you may want to build or expand functionality and accessibility. It is for that reason we chose to switch it to python in December 2022. Python is easier to read but also allows for more options in its function. This new version was designed to consistently be on your screen and to be useful in many different situations. The application itself does not enable anything special you couldn’t do on your own, but instead works to make it easier to accomplish these tasks.\nTech Desk Tools is designed specifically to be used at the University of St. Thomas and operates behind the scenes using things we have and maintain on campus. For that reason should you try to run this at another university or off campus the application will lock away a lot of functionality."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/TDTPython.html#front-page-left-side-explanations",
    "href": "Sections/Portfolio/PortProjects/TDTPython.html#front-page-left-side-explanations",
    "title": "Tech Desk Tools",
    "section": "Front Page (Left Side Explanations)",
    "text": "Front Page (Left Side Explanations)\n\n\nPrimary Functions\n\nFour Main Buttons:\n\nOpen Main Apps - Opens Applications used commonly at the Tech Desk, the applications change based on senior student title or regular student\nTech Desk Menu - Opens the standard Tech Desk Training menu in the knowledge base\nEnter Hours - Opens the hour enter page within Murphy Online in the employee portal. This does require you to sign in with your normal UST account\nScreenshot - Opens the screenshot tool for windows, should be used to aid documenting issues\n\n\nHave a Question?\n\nContains two buttons, one that opens the KB and one that opens Bing. If there is anything typed and you press a button, it searches in desired engine, by default if you type something and press enter it will search in Bing. This is purposeful, and due to us being a Microsoft campus, the Bing search at times is able to link directly to UST specific help or information relevant to us as a campus. \n\n\n\nAsk First Call Response\n\nProvides a textbox and button that when clicked will open and type the text in first call response, note that it does not send it in case something lags. If you just click the ask for help button it will simply open the First Call Response channel in teams  \n\nTabs with further options seen below\n\nHome, Applications, Directory, Get Info, and Senior Students"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/TDTPython.html#home-tab",
    "href": "Sections/Portfolio/PortProjects/TDTPython.html#home-tab",
    "title": "Tech Desk Tools",
    "section": "Home Tab",
    "text": "Home Tab\n\nStandard Request Button\n\nThis button will take you directly to a form for creating a basic ticket\n\nPriority Zero\n\nThis button will take you directly to the form for creating a Classroom or Event Emergency\n\nNote Space\n\nThis is a temporary note space. Can be used for collecting information from clients or ranting, as you see fit. Please note that text entered does not saved at all and cannot be recovered\nIf the user who is actively signed in is not a member of the Tech Desk or the program is not able to get their permissions this space will show a different text."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/TDTPython.html#applications-tab",
    "href": "Sections/Portfolio/PortProjects/TDTPython.html#applications-tab",
    "title": "Tech Desk Tools",
    "section": "Applications Tab",
    "text": "Applications Tab\n\nOrganized buttons separated based on Tech Desk Links, General Student Links, and Password Resets. \nTech Desk Links - has almost any link that might be needed for work purposes. The links will launch via incognito if needed but should not when logged in as an XST, this excludes MIM.  \n\nFor MIM you need to log in using your standard UST account which is prompted following clicking the button.\n\nStudent links - Common links used by all/most students. Included both for the use of the Tech Desk students as well as for getting URLs for referring student callers to.\nPassword Resets - Provides:\n\nA quick link button to the #TD KB on resetting a password.\nA button to open ADAC (the password reset tool/app).\nA button linking to the Main, University public KB on password resets\nPassword Generator - This creates passwords based off words coded into the application, the passwords will always be sufficient for the UST requirements. It is not recommended to keep these passwords and should set it to something more meaningful afterwards"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/TDTPython.html#directory-tab",
    "href": "Sections/Portfolio/PortProjects/TDTPython.html#directory-tab",
    "title": "Tech Desk Tools",
    "section": "Directory Tab",
    "text": "Directory Tab\n\n\nThe contact info page consists of many different departments which Tech Desk often must refer people too. It also contains UST Houston’s phone number for when needed. \n\n\nThe text under the “email@stthomas.edu” header is the leading part of the email address. All you need is the @stthomas.edu after any of them.\n\n\nThe phone numbers for campus are all 651 (unless specified), and the extensions for the departments are the last five in the number listed."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/TDTPython.html#get-info-tab",
    "href": "Sections/Portfolio/PortProjects/TDTPython.html#get-info-tab",
    "title": "Tech Desk Tools",
    "section": "Get Info Tab",
    "text": "Get Info Tab\nPreviously named CMD, this was renamed to Get Info to reiterate its function. \nCMD or Command Prompt, is the default terminal for windows that can communicate directly with the operating system and system. This tab simply runs commands in a hidden terminal window and returns the output into the respective box. All of the commands can be run manually by anyone, with some additional commands requiring admin credentials. \n\nUser Info - Enter the user’s name and enter/return and the CMD info about the user will be output to the open window below. The username clears after entering.\n\nThe manual function this completes would be to Open Window Command Prompt, type “net user %Username% /domain”, press enter\nIf you enter the username wrong or it does not exist an error message will show with some additional instructions\n\n\nPing - Enter the asset number of the device or the web URL and pressed enter/return, availability of the device on the network or website will be output to the open window below.\n\nThe manual function this completes would be to Open Window Command Prompt, type “ping %AssetOrUrl%”, press enter\nAs with above, if something isn’t working it will show an error message and additional info"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/TDTPython.html#senior-students-tab",
    "href": "Sections/Portfolio/PortProjects/TDTPython.html#senior-students-tab",
    "title": "Tech Desk Tools",
    "section": "Senior Students Tab",
    "text": "Senior Students Tab\n\nProvides links to websites and apps that would be used by a Senior student. They all require additional permissions and credentials to access, some of which are not granted even when appointed too senior student.\nThese include:\n\nLAPS - Local Admin Password \nAzure - used to reset MFA’s\nIntune - Online Microsoft Device Managment software\nJamf - Apple Managment software\nSalesForce -  Currently a work in progress with very few people having access. This requires completion of formal FERPA training\nAdobe Admin - Able to check active licenses for Adobe Acrobat and Creative Cloud.\n\nIt also contains links to KBs with guidelines for the use of these sites/tools.\nThe Final button opens the senior student menu which contains much more information and many more guides. It is expected that Senior Students know the information contained within the menu."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/TDTPython.html#maintenance-of-application---for-st.-thomas-its",
    "href": "Sections/Portfolio/PortProjects/TDTPython.html#maintenance-of-application---for-st.-thomas-its",
    "title": "Tech Desk Tools",
    "section": "Maintenance of Application - For St. Thomas ITS",
    "text": "Maintenance of Application - For St. Thomas ITS\n\nDeployment/Installing Tech Desk Tools\nIf needed, you can run the PS1 script and provided the asset list is correct it will deploy Tech Desk Tools to all assets within that list. Please be aware you need admin in order to run the script. If needed you can also simply copy the exe to the computer and run it like that, I do warn that Microsoft has been flagging it as a trojan due to it running CMD commands upon opening, the script fixes that. \nFor additional information you can open the PS1, it has more instructions and more details. \n\n\nUpdating the App\nThe application is written in python and contained within a single .py file. Should you need to edit it, you will need to download the most recent version of python to a computer and an editor. I personally use VS Code. At the top of the .py file I wrote a loop that installs all needed packages within the file, I recommend creating a new .py file and running the loop out of that or just in the terminal.\nThe application contains instructions about what things do to the best of my ability. If questions arise just reach out to me. The layout of the app and the GUI library takes some getting used to, but it is easier once looking at it a bit, it is difficult to explain ever single line in the GUI. I should add it is still much simpler than alternatives which is why I chose to use it."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/TDTPython.html#reason-for-some-choicesfaq",
    "href": "Sections/Portfolio/PortProjects/TDTPython.html#reason-for-some-choicesfaq",
    "title": "Tech Desk Tools",
    "section": "Reason for some choices/FAQ",
    "text": "Reason for some choices/FAQ\n\nWhy is it a single .exe file\nSimplicity. I tried making the app run from a directory of folders and while it launched a tiny bit faster, it made it extremely difficult to update the application. Another reason I switched it was the size reduction that came from making it a single file, it was about 50-60mb less. \nI am not a software engineer by any means and the realistic options we have for updating the application require manual placement of the app on the computers or using a script to automate it remotely. When trying to remove a directory (Folders) it would fail due to the computer not being able to close the app and its processes, so we couldn’t delete it when people were working. This left me several times waiting until after 10pm or waking up at 5am to remotely restart computers to kill the processes and deploy the application, which would at times take over 2 hours to copy every file and folder to each computer.\nWith the single exe file, we are not only able to kill the process at anytime, but also due to the reduced size the install/update time shortens to under 4-5 minutes.\n\n\nWhy is the source code contained within a single file instead of containerized\nGrowing off the above, simplicity. \nI also prefer writing several files and calling them from within my code, it makes it nicer and cleaner. I think the source code is around 1800 lines of code so it is very overwhelming initially, it also at points is messy and not the cleanest code to look at.\nThe downside however of creating seperate files is needing to keep track of all the dependent files, for the sake of future upgradability I chose to contain the entire application and anything dependency I would normally contain in separate files within the actual .py file. My hope is that it makes updating simpler in the future, I have found it so when needing to compile it into an exe. \n\n\nWhy Python - More Specifics\nPython is not the first choice for desktop application development typically due to how it operates and interacts with the computer. C, C#, C++ are sort of the gold standard for their speed and at times stability. Python however unlike those is very easy to write and extremely easy to read due to its syntax being very similar to common English. It is also a language often used for introductory programming classes, its simplicity makes it easy to learn for those new to coding, but powerful for those who already do know how to code.\nFor what we need and use at the Tech Desk, and as I found the limits placed on us in regard to permissions, python offered a significant upgrade in functionality not possible in AutoHotKey without losing any of the functionality previously maintained by the older application, there is even several libraries that mimic AHK within python.  \n\n\nDesign Choices\nI’ll be the first to admit that its not perfect, but its better.\nI tried out several renditions of layouts and ideas we had relating to how it was organized and what would be available within the application. With the amount of info contained and easy of getting to it quickly the tab approach was best for what I was able to do within the python GUI library. The Home/Main page which doesn’t change contains things that you are expected to use in some fashion, the application is simply there to make it easier to do them, that follows for most of the information. Nothing within the app requires the application, but it makes it quicker or simpler. And that’s what the aim of the program is. \n\nI hope this continues to be helpful for a while. Thank you :)"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/BSRef.html",
    "href": "Sections/Portfolio/PortProjects/BSRef.html",
    "title": "Biostat Reference Guide",
    "section": "",
    "text": "This is a markdown adapted version of the pdf also available in the repository. If there are typo’s, information I should add, or simply things I did wrong please let me know and I can update it. Additionally this markdown will contain additional depth since I can fit it in.\nCurrently this markdown lacks proper formating for the code and lacks the color coding present in the pdf copy. At some point I plan to add actual code with working examples.\nThis was a project completed for Biostatistics 6451 at the University of Minnesota. The documents are here to serve as a reference to anyone who would like them. I hope they are found useful\n-Jonathan\n\nWhat Is R\nSteps of Analysis\nWriting Reports (Non-academic)\nBasics of R\nImportant Maybe Not So Basics\n\nConditionals\nData Structures and Types\nTypes of Data – Review\nGlobal R Options\n\nFunctionality\n\nPackages\nPackages Used\nInstalling and Loading Packages\nData Loading\nDirectories and File Paths\nData Processing (Forcats, Dplyr)\nSummary Statistics\nCreation of Visuals - Tables\nCreation of Visuals - Charts\n\nStatistical Models\n\nGeneral Format\nLinear Regression\nLogistic Regression\nPoisson Regression\nSurvival & Cox Regression\nOrdinal Regression\nLog-Binomial Regression\nModel Selection"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/BSRef.html#welcome",
    "href": "Sections/Portfolio/PortProjects/BSRef.html#welcome",
    "title": "Biostat Reference Guide",
    "section": "",
    "text": "This is a markdown adapted version of the pdf also available in the repository. If there are typo’s, information I should add, or simply things I did wrong please let me know and I can update it. Additionally this markdown will contain additional depth since I can fit it in.\nCurrently this markdown lacks proper formating for the code and lacks the color coding present in the pdf copy. At some point I plan to add actual code with working examples.\nThis was a project completed for Biostatistics 6451 at the University of Minnesota. The documents are here to serve as a reference to anyone who would like them. I hope they are found useful\n-Jonathan\n\nWhat Is R\nSteps of Analysis\nWriting Reports (Non-academic)\nBasics of R\nImportant Maybe Not So Basics\n\nConditionals\nData Structures and Types\nTypes of Data – Review\nGlobal R Options\n\nFunctionality\n\nPackages\nPackages Used\nInstalling and Loading Packages\nData Loading\nDirectories and File Paths\nData Processing (Forcats, Dplyr)\nSummary Statistics\nCreation of Visuals - Tables\nCreation of Visuals - Charts\n\nStatistical Models\n\nGeneral Format\nLinear Regression\nLogistic Regression\nPoisson Regression\nSurvival & Cox Regression\nOrdinal Regression\nLog-Binomial Regression\nModel Selection"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/BSRef.html#what-is-r",
    "href": "Sections/Portfolio/PortProjects/BSRef.html#what-is-r",
    "title": "Biostat Reference Guide",
    "section": "What Is R",
    "text": "What Is R\nIn the simplest terms, R is a calculator, often chosen by statisticians and data visualizers due to its vast package support and standards.\nMore complicatedly, R is a functional programming language with aspects of an object-oriented one written in C and Fortran, though less rigid. Computationally, R is slow and utilizes only a single computer core and RAM, which may not impact most tasks unless dealing with large datasets or complex algorithms. However, R compensates with its rich ecosystem of packages, oRering extensive functionality for statistical analysis, data manipulation, visualization, and more, making it a popular choice for both beginners and experienced data scientists alike. Additionally, its open-source (Publicly available) nature fosters a vibrant community where users can collaborate, contribute, and continually improve the language and its capabilities. Python is a common comparison; it oRers better computational optimization and better flexibility for tasks beyond statistics however it lacks package quality standards, many of the visualization tools, and statistics specific functions. The other comparison is SAS which falls on the opposite side of the spectrum; it is typically seen as less daunting and simpler but lacks many of the tool’s R and python have easily available. SAS does have extensive package support, testing before release, and isn’t open source making it the choice of government for stability, at a cost."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/BSRef.html#steps-of-analysis",
    "href": "Sections/Portfolio/PortProjects/BSRef.html#steps-of-analysis",
    "title": "Biostat Reference Guide",
    "section": "Steps of Analysis",
    "text": "Steps of Analysis\n\nWhat is your question?\nGather and Process Data\nExploratory Data Analysis (EDA)\nChoose Analysis or Model Technique(s)\nConduct Analysis\nInterpret Results\nCommunicate Findings of Analysis"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/BSRef.html#writing-reports-non-academic",
    "href": "Sections/Portfolio/PortProjects/BSRef.html#writing-reports-non-academic",
    "title": "Biostat Reference Guide",
    "section": "Writing Reports (Non-academic)",
    "text": "Writing Reports (Non-academic)\nIntroduction (1)\nData (2) – Who, What, Where, When, How many\nExploratory Data Analysis (3) – Chart Time!\nMethods (4) – Try to explain your brain process\nResults (5 & 6)– Get output, explain output\nConclusion (7) – explain output (Non-Statistically)"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/BSRef.html#basics-of-r",
    "href": "Sections/Portfolio/PortProjects/BSRef.html#basics-of-r",
    "title": "Biostat Reference Guide",
    "section": "Basics of R",
    "text": "Basics of R\nFunctions – Similar to math, these take input and produce an output. All functions have inputs; these can Be populated or require input. If you are ever confused about what a Function does or its inputs ( params ), Simply type? function in the console And the documentation will appear.\nAssign output to a variable Like this:\nOut &lt;- Function ( Input ) ; &lt;- is assign\nAdditionally, get data like this:\nVar &lt;- Data$Var"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/BSRef.html#important-maybe-not-so-basics",
    "href": "Sections/Portfolio/PortProjects/BSRef.html#important-maybe-not-so-basics",
    "title": "Biostat Reference Guide",
    "section": "Important Maybe Not So Basics",
    "text": "Important Maybe Not So Basics\n\nConditionals\nConditional (Booleans) – “If” statements; For computer science TRUE/T = yes or 1; FALSE/F = no or 0. Conditionals are: If T then X, else (if not X) then Y\nBesides the typical less then or greater then you can use! to indicate not.! is.na () would return False for NA values, when it normally would give True. Additionally you can use == to specify something to match. “Apple” == “Apple” ; TRUE\nSimilarly, when attempting to bunch conditionals use | to say or, and use & to say and. Ifelse ( Data, X &gt; Y & X &lt; Z ) is saying X larger then Y but smaller then Z.\n\n\nData Structures and Types\nData Storage and Types in R: At the base of computational statistics and programming is data and data structures. These not only have diRerent uses but using the wrong types can cause issues in functions.\nVectors – single dimension that can hold a single type of data; highly eRicient.\nMatrices – Two-dimension storage of only numeric data; allows for matrix math and is more eRicient.\nData Frames – The most common. two-dimension storage that allows columns to have diRerent types of data; IneRicient and slow but allows for superior data manipulation of all types.\nLists – The holder, allows for storage of other data structures; slow and require careful syntax\nArrays – Matrices with additional dimension; eRicient, supports math, but is memory intensive.\nTibbles – essentially a data frame with extra features; can cause issues in functions.\n\n\nTypes of Data – Review\nNumeric Continuous : Measure 79.2, Heart rate Discrete : Count 1,2,3…, I have one cat\nFactors (Categorical) Ordinal : Groups with Order 1 - 5 scale, income group Nominal : A group without order Nationality or Ethnicity Binary or Indicator: 0 or 1; Yes or No\nIn R these often are considered only These unless you specify\n\n\nGlobal R Options\nJust some basics that can be incredibly useful.\nOptions(scipen = 999 )\nThis will stop R from reporting large digits in scientific notation\nOptions(digits = 3 )\nThis will set default rounding in R to 3 or what you please. This does not always work\nSet.seed( n )\nThis normally is not always important. However if you randomize or bootstrap this will make it reproducible by others."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/BSRef.html#functionality",
    "href": "Sections/Portfolio/PortProjects/BSRef.html#functionality",
    "title": "Biostat Reference Guide",
    "section": "Functionality",
    "text": "Functionality\n\nPackages\nWhat is a package? Packages, or libraries (for our case they are the same), are collections of functions or tools which can be used to perform a task. In R many of the packages revolve around data and statistics making these packages essential to most of the work we do in R. Often they are significantly faster than we could write ourselves, not only because they already exist, but because they a written in a faster programming language and then use R as an interface. Simply, if a function exists in a package, use that one.\n\n\nPackages Used\n\n\n\n\n\n\n\nPackage\nDescription\n\n\n\n\nTidyverse\nCollection of common packages essential for most people\n\n\nTidymodels\nCollection of packages for model testing and training\n\n\nPsych\nUsed for summary statistics functions\n\n\nGgstatsplot\nCool plots, not essential\n\n\nGgpubr\nUsed for themes, creating tables/charts for publication\n\n\nGgtexttable\nCreate tables from existing dataframes\n\n\nGtsummary\nUsed in creation of Table 1 (lifesaver)\n\n\nFlextable\nSame as above\n\n\nRColorBrewer\nUsed to choose non-standard colors of plots\n\n\nGgfortify\nUsed for a couple of things, truthfully not sure how to explain\n\n\nJtools\nStatistical test output\n\n\nResourceSelection\nStatistical test output\n\n\nLmtest\nStatistical test output\n\n\nCar\nUsed for a couple things normally, for us statistical test output\n\n\nSurvival\nCore package of survival analysis\n\n\nMultcomp\nStatistical test output\n\n\nSurvminer\nBuilds on survival, can be finicky\n\n\nMASS\nStatistical test output, model selection\n\n\nVGAM\nOrdinal regression\n\n\nGgcorrplot\nFun way to visualize correlation plots\n\n\nAER\nTesting Dispersion\n\n\n\n\n\nInstalling and Loading Packages\nInstall.packages(\"Lib\") \nLoad installed packages:\nlibrary(Lib) \nTo use a function from a specific package do:\npackage::Function()\n\n\nData Loading\nReadr : Common Package used for various types of data Readxl: Package to read excel files Haven: Package developed to read SAS file outputs Code Example\nData &lt;- read_csv(\"File_Path\")\n“csv” can be replaced with specific file of interest. Xlsx has some weird extra parameters so just don’t use them. Excel will make you sad.\n\n\nDirectories and File Paths\nDirectories are where the computer or software wants to choose files from.\nAn example path would be /Users/YourAccount/Folder where each instance after the / is a different directory; the Users directory contains the YourAccount directory and that contains your files.\nYou can change this by doing:\nsetwd(\"Path\")\nWhen entering the path make sure to “/” for paths. I often find when you copy it will use “\\”, particularly on windows\nOnce you are in a set directory to access a file or folder in current directory use “./” Additionally to access a file one directory back “../” ; so using the above if you’re in the Folder but need to access another folder in the YourAccount directory you would do “../Folder2”\n\n\nData Processing (Forcats, Dplyr)\nThe following can be combined with tidyverse pipes; you don’t need to specify data within the function permitted the variable exists in the input. For more information I suggest this book from the creator.\nData pipe example\nNewData &lt;- Data %&gt;% Function()\nProcessing Functions\nAs.XXX such as as.numeric(), as.factor() – Used to change how R sees variables. For example we may see 1 and 0 as binary but R may not and think it’s a number. Check this using the str() function.\nYou can change that by doing the following:\nVar &lt;- as.factor(Binary_Var)\nMutate: Used to create new variables or change existing ones\nData %&gt;% mutate(NewVar = Function(OldVar ))\nIfelse: Base conditional; if x, then A, else, B – Useful for creating indicators\nifelse(Data, Conditional(Var), Then, else )\nCase_when() or Fct_recode() – Both are usedto change variables but is cleaner than doing multiple ifelse() functions\nData %&gt;% case_when(conditional ~ \"Category A\", conditional ~ \"Category B\", TRUE ~ \"Other\") \nNote: TRUE = Cases not captured by conditional\n\nmutate(NewVar = fct_recode(Var, `Level1` = \"1\", `Level2` = \"2\"))\nSubset(), Select(), Filter() - All Similar function to get more specific data\nsubset(Data, conditional1 & conditional2) - Get rows match conditional\n\nselect(Data$Column1 , Data$Column2 ) -- select specific columns\n\nfilter() -- Nearly exact to subset but more eRicient with larger data\nRelevel() – Set the group you want as Null, or want compared against.\nrelevel(Factor_Var, Ref ) ; Ref is the group you want compared too\n\n\nSummary Statistics\nKey Functions\nStr(Data) – provides high level overview of data, its variables, and types\nround(Data, round = n) – when numeric is inputted, it will round to n\ndescribe(Data$Var) – provides summary statistics (mean, med, sd, iqr,…)\ndescribeBy(Data$Var, group = Data$Group_Var) – Similar but by grouping variable\nsummary(Model) ; Summ(Model) – both of these exist to give output from models.\nSummary is built into R although summ gives more information\ntidy(Model) – creates a “tidy” data frame as output for models\nTable() and prop.table() can be used to give information about two categorical variables.\nPlacing the output of table() into prop table will give the proportions of the groups.\ntable(Row_Var, Col_Var)\nT-test\nt.test(Var, Group,\nalternative = \"two.sided\")\nbesides running a t-test, providing only a continuous variable will return the confidence interval ; for models use confint(Model)\nCorrelations normally will require you to filter NA’s using na.omit(Data)\ncor(Data)\nto specify two rows of data:\ncor(Var1, Var2)\nAlternatively, if you don’t want to remove NA’s:\ncor(Data, use = \"pairwise.complete.obs\") -- This will impute NA's\n\n\nCreation of Visuals - Tables\nTable 1\nTable &lt;- tbl_summary(data = Data, include = c(Var1, Var2,....),\nby = Group_Var,\nstatistic = list(all_continuous() ~ \"{mean} ({sd})\", all_categorical() ~ \"{n} ({p}%)\"),\nlabel = list(Var1 ~ \"Full Name\"),\nmissing = \"no\",\ndigits = all_continuous() ~ 2 ) %&gt;% \nadd_n() %&gt;%\nadd_overall() %&gt;%\nmodify_header(label = \"TableTitle\") %&gt;% \nmodify_spanning_header(c(\"stat_1\", \"stat_2\") ~ \"**Group_Var**\") %\\&gt;%\nadd_stat_label() ; for each level in group add additional \"stat_n\"\nThis is one of few functions which gives clear errors and help.\nGgtexttable – Allows to convert dataframe to table output easy\nTable &lt;- ggtexttable(Data, rows = c(\"Row1\",...) ,\ncols = c(\"col1\",...) ,\ntheme = ttheme(\"theme\")) %&gt;%\ntab_add_title(text = \"title\")\nTip: use the tidy function to create a data frame you can input here\n\n\nCreation of Visuals - Charts\nWhat and What to Use (Briefly)\nSingle continuous – Histogram + density\nContinuous and Categorical – Boxplot + violin\nTwo continuous – point (scatter) + Smooth (line)\nDiscrete and categorical – Column\nColor\nWhen using R you have the ability to set colors by using names such as “blue” or using hex code (#0000FF). In ggplot the default color palette is set up to be colorblind friendly and encourage thinking about that.\nggplot Core function\nGgplot(Data, aes(x = Var1, y = Var2, fill = \"Color\", alpha = opacity)) +\ngeom_XXXX() +\nggtitle(\"Title\") +\nxlab(\"X Axis\") +\nylab(\"Y Axis\")\nGeom’s are the code for types of plots; geom_hist () = histogram The aes() block can be specified in the initial function or if you want to plot diRerent variables, or even datasets you can put it inside of the geom.\nAdditional things\nTo add things to a ggplot simple just put a + and then function.\n + Facet_wrap(.~Group, scales = \"free\" )\nUsed to produce multiple plots by group. If you specific scale = free, the x and y can use different mins and maxs\n + Coord_flip() \nShould you have too many categories this will flip x and y. This will produce a tall plot instead of a wide plot; useful for documents\n+ Geom_point()\nThis is your scatterplot geom; other geoms are normal\n+ Theme()\nThis is customization function. It allows you to alter every single aspect on a ggplot from subtle movements of elements, removing the legend, or changing the font. While not complicated, it is dense.\nOther oddities\nwhen trying to change the color, one would think it is the color option, that however often changes the outline. The fill option changes main color.\nOften times ggplot will have packages built on top of it, meaning external functions will use ggplot to produce output. This can be seen with autoplot() , and the survminer package. Additionally, using the correlations, we can use the ggcorrplot package and the ggcorrplot () function to produce a heatmap. This makes it easy to visualize correlations\nGgcorrplot(Cor_Data)"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/BSRef.html#statistical-models",
    "href": "Sections/Portfolio/PortProjects/BSRef.html#statistical-models",
    "title": "Biostat Reference Guide",
    "section": "Statistical Models",
    "text": "Statistical Models\n\nGeneral Format\nThe following pages are arranged to attempt to give a background of what these things are, when you’d want to use them, and why. Then the code will be given, followed by assumptions, and lastly some limitations.\nGeneral things in regression:\nP Fishing: Adding more variables usually will make a model more significant; that doesn’t make it more useful. Additionally, having 30, participants is amazing; it also makes most things significant. Look beyond P.\nOverfitting: due to us rarely having every possible data point, when designing models to be used outside of an analysis it is important to not include too many variables. This may result in the model being super predictive of your dataset, but not others.\n\n\nLinear Regression\nWhat, When Why\nUsed for understanding relationships between continuous variables.\nHow\nlm_model &lt;- lm(Y ~ X1 + X2,\ndata = YourData) ; can also use glm()\nAssumptions\n\nL: Linearity\nI: Independence\nN: Normality\nE: Equal Variance Can be checked using plots the autoplot() function from ggfortify\n\n\nautoplot(lm_model)\nProduces: Residuals vs Fitted, Q-Q plot, Scale Vs Location, Cooks\nOther ways to check assumptions\nshapiro.test(residuals(lm_model)) -- Normal residuals (Normality)\nbptest(lm_model) -- Homoscedasticity (Equal Variance)\ncar::vif(lm_model) -- No Multicollinearity (independence)\nLimitations\n\nLimited to Additive Relationships: Linear regression struggles with capturing interactions or non-linear relationships.\nLimited Extrapolation: Linear regression is not suitable for making predictions outside the range of observed data.\nAssumption of Linearity: Assumes linear relationships, may miss complex patterns which often exist in life.\n\n\n\nLogistic Regression\nWhat, When Why\nEstimates the probability of binary outcomes, often used for classification. It’s valuable in predicting the likelihood of events or binary responses.\nHow\nlogit_model &lt;- glm(Y ~ Predictor,\ndata = YourData,\nfamily = \"binomial\")\nAssumptions\n\nIndependence\nLinearity of Log Odds\nNo Multicollinearity (see Linear Regression; vif()\n\n\nfitted_values &lt;- predict(logit_model, type = \"link\") \n\nggplot(data, aes(x = independent_var, y = fitted_values)) +\ngeom_point() +\ngeom_smooth(method = \"lm\", se = FALSE)\n\nGOF &lt;- hoslem.test(Outcome_Var, fitted(logit_model) )\nLimitations\n\nNeed Binary Outcome - Inflexible compared to advanced statistical methods.\n\n\n\nPoisson Regression\nWhat, When Why\nModels count data, assuming events occur independently at a constant rate over time/Space. Suitable for analyzing rare events or incidence rates.\nHow\npoisson_model &lt;- glm(Y ~ Predictor, data = YourData,\nfamily = \"poisson\")\nIf over dispersed: family = quasipoisson(link = \"log\")\nVariable Denominator\npoisson_model &lt;- glm(Outcome ~ Predictor, data = YourData,\noffset = log(Offset_Variable),\nfamily = poisson(link = \"log\"))\nAssumptions\n\nCount Data: Assumes the outcome variable is counts of events.\n\n- Independence: Assumes observations are independent.\n\nLinear Log Rates: predictors and log rates have linear relationship.\nHomogeneity of Rates: Assumes variance equals the mean\n\n\ndispersiontest(poisson_model)\nLimitations\n\nAssumes Equal Mean and Variance: assumes variance equals mean, often unrealistic.\n\n\n\nSurvival & Cox Regression\nWhat, When Why\nAnalyzes time-to-event data, considering censoring and identifying factors affecting survival probabilities. Cox Proportional Hazards Model is particularly useful for estimating hazard ratios.\nCensoring\nCensoring in survival analysis is when some subjects’ outcomes aren’t observed within the study period, often due to loss to follow-up.\nHow\nCox_model &lt;- coxph(Surv(Time, Event) ~ Predictor, data = YourData)\nAssumptions\n\nProportional Hazards: Hazard ratios are constant over time.\nIndependence of Censoring: Censoring is non-informative.\n\n\nCox_Sum &lt;- Cox.zph(Cox_model)\nGgcoxzph(Cox_Sum)\nLimitations\n\nProportional Hazards: Violations can lead to biased estimates.\nIndependence of Censoring: Assumes that censoring is unrelated to the outcome.\n\n\n\nOrdinal Regression\nWhat, When Why\nModels the relationship between predictors and ordered categorical outcomes. It’s beneficial for analyzing data with ordered response levels.\nHow\nOrdinal_model &lt;- polr(Ordinal ~ Predictor, data = YourData)\nAssumptions\n\nProportional Odds: Odds of higher outcome categories versus lower ones are constant across predictor levels.\nIndependence of Observations: Observations are independent.\n\n\ntestpoe(Ordinal_model) -- Test for Proportional Odds\nLimitations\n- Proportional Odds: Violations indicate diRering relationships between predictors and categories. - Personally dislike this method because it seems odds for interpretation; multinomial regression can be accomplished by using family = multinomial() in glm, but doesn’t factor order\n\n\nLog-Binomial Regression\nWhat, When Why\nEstimates relative risks directly for binary outcomes, providing straightforward interpretations of predictor effects\nHow\nLB_model &lt;- glm(Dependent ~ Predictor,\ndata = YourData ,\nfamily = binomial(link = \"log\"))\nAssumptions - Binomial Distribution: Outcome variable follows a binomial distribution. - Log-linearity: Predictors have a log-linear relationship with the log- odds.\nLimitations\n\nConvergence Issues: May not converge, especially with small sample sizes or high outcome prevalence.\n\n\n\nModel Selection\nWhat, When, Why\nUse the computer to select model covariates to optimize the model. I believe this is most useful for predictive models although in data where little is known about covariates it can provide useful insight.\nHow\nfull_model &lt;- lm(y ~ ., data = data)\nstepwise_model &lt;- stepAIC(full_model, direction = \"both\")\nNotes: Direction can be “both”, “forward”, “backward” Forward : Start at empty model and add important variables Backward : Start at full model and remove variable with minimal impact Both : Start at nothing and add, however allows computer to remove or go backwards to provide optimal output\nLimitations\n\nComputational Demand: Realistically you always want to use both in prediction as it will always provide the best output (forward is good for discovery though). However, in cases where your model has extensive dimensions you may opt for forward or backward due to computational demand of using the “both” setting with lots of data."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/MappingMisery.html",
    "href": "Sections/Portfolio/PortProjects/MappingMisery.html",
    "title": "Mapping Misery",
    "section": "",
    "text": "Health metrics often highlight improvements in physical and mental outcomes over time or often prioritize on life expectancy to outline success. However, these broad measures can obscure a critical reality: many individuals are not just living longer—they are experiencing more days of poor health and suffering. For those burdened by physical limitations, chronic illness, mental health challenges, or realizing your own brain is destroying itself, each additional year can represent an increase in cumulative physical and emotional strain rather than an improvement in quality of life.\nBeyond simply adding years, disparities in health outcomes mean some individuals endure disproportionately higher levels of pain, stress, and poor health conditions over their lifetimes. These disparities are not evenly distributed; they are influenced by socioeconomic status, access to healthcare, and other structural inequities such as location as well as historical and current political influence. This results in a troubling pattern where the lived experience of health diverges sharply from the abstract gains reflected in numbers. Quantifying this burden is essential to understanding the human impact of poor physical and mental health days. By analyzing patterns in the data, we can move beyond surface-level improvements to identify and address the underlying drivers of suffering, ensuring that efforts to improve public health translate into both longer and better lives for all individuals."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/MappingMisery.html#pre-preprocessing-and-clustering-methods",
    "href": "Sections/Portfolio/PortProjects/MappingMisery.html#pre-preprocessing-and-clustering-methods",
    "title": "Mapping Misery",
    "section": "Pre-Preprocessing and Clustering Methods",
    "text": "Pre-Preprocessing and Clustering Methods\nBefore looking to predict poor physical and mental health days, I wanted to determine a method to implement historical trends for each county, state, and the country overall. These trends contained metrics in premature death, uninsured adults, primary care physicians, preventable hospital stays, unemployment rate, children in poverty, sexually transmitted infections, mammography screening, uninsured, dentists, uninsured children, air pollution – particulate matter, alcohol-impaired driving deaths, flu vaccinations, and school funding starting in 1997 always up to 2022. For my purposes I filtered out trends before 2008. I then imputed missing values with the mean of those 14 years for the specific county and measure. For school funding, Vermont’s counties were set to be the average Vermont spent as they fund schools as a state, and not by county. Additional metrics created included: yearly difference between state and country for each metric; average variability over the 14 years for county and state; average difference between state and country; and the coefficient of variance. All for each of the 15 original measures for all years and ranges between 2008 and 2022.\nThe last required component (foreshadowing) for allowing these trends to contribute effectively to the model was dimension reduction. In total I had 634 variables across 3196 observations (Country, 52 States, 3143 counties). The initial choice was to conduct a PCA with GMM clustering, setting NAs as their own group. The second choice was to instead conduct an MCA by turning all 634 variables into categories with 7 levels and an additional 8th to represent NA’s and again using GMM clustering. Objectively I believe PCA worked more effectively but using MCA permitted using missing values as an explanatory feature.\n\n\nMap 1: Behold the new US regions"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/MappingMisery.html#demographics-and-cluster-outcomes",
    "href": "Sections/Portfolio/PortProjects/MappingMisery.html#demographics-and-cluster-outcomes",
    "title": "Mapping Misery",
    "section": "Demographics and Cluster Outcomes",
    "text": "Demographics and Cluster Outcomes\nAs outlined above, while PCA is more effective and efficient I cared more about using missingness as a feature. This almost exclusively because it can speak to available resources to report measures. Clusters from here on refer to GMM clusters of the MCA.\nSeen below is Table and the base demographic trends by cluster with an overall column for comparison:\n\n\nWithout diving in specific to each cluster I wanted to highlight some numbers or oddities. Of the 10 clusters, only 3 contain less than 100. Interestingly, one of these is 100% rural, and the ninth cluster, which was assigned to the United States as a whole, largely consists of all Alaskan counties. For purposes of what I’m trying to predict, the overall number of poor physical health days per 30 days is 3.5 with cluster 7 being the lowest at 2.88 and cluster 5 highest at 4.13. For poor mental health days America averages 4.79 days per 30 with cluster one being the higher at 5.2 closely followed by cluster 5 at 5.1; cluster 9 and cluster 6 have the two lowest at 4 and 4.1 respectively. It’s very fitting the cluster with America and the most Rural cluster have the lowest.\nWhen observing the maps below, we see the counties representing the southern united states all fall in clusters with higher poor physical health days per 30. This is s similar trend for mental health days however this is less defined and proven harder to explain.\nMap 2: A higher number or movement away from blue represents number of expected days above the center mean."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/MappingMisery.html#alternative-approaches",
    "href": "Sections/Portfolio/PortProjects/MappingMisery.html#alternative-approaches",
    "title": "Mapping Misery",
    "section": "Alternative approaches",
    "text": "Alternative approaches\nAfter successfully having the MCA work in clustering counties I would find it interesting to convert all of the numerical metrics to categories, allowing for NAs as a group. I normal settings I think it wouldn’t be as impactful but when thinking about counties it can reflect political influence, beliefs, or lack of resources. I’m also looking to play around with one-hot encoding on a mass scale and using component analysis in a similar fashion to MCA to see how efficient it could be."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/MappingMisery.html#limitations",
    "href": "Sections/Portfolio/PortProjects/MappingMisery.html#limitations",
    "title": "Mapping Misery",
    "section": "Limitations",
    "text": "Limitations\nI didn’t adjust for state like I was originally planning too and when looking at the residual map some appear very clearly on state lines. I hoped the clustering would address some of that but not properly. The other thing is mental health again just proves hard to predict, but physical ailment is extremely viable.\nWhen I looked at the residuals my concern was not so much if it was missing, but if it was missing in the right direction. This means if the expected difference from the center mean is negative (less), then it was predicting a negative number. I found that several counties, largely on the west coast, were proving more difficult to predict. The reason I care about the direction is because I plan to make the outcomes into indicators to see if I can predict risk next."
  },
  {
    "objectID": "Sections/Hobbies/index.html",
    "href": "Sections/Hobbies/index.html",
    "title": "Jonathan Barnes",
    "section": "",
    "text": "Things in my spare time\nHome Cooking, sometimes baking, and Plants\nExercising. Weightlifting & Walking along Mississippi mainly\nAnd as always floor time with my cat."
  },
  {
    "objectID": "Sections/Resume/index.html",
    "href": "Sections/Resume/index.html",
    "title": "Resume",
    "section": "",
    "text": "Note: On some devices the file will not render properly. In that case please click download to view the PDF\n\n\n   Download Resume"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/SPHereSurvey.html#results-and-aspects-by-use-frequency",
    "href": "Sections/Portfolio/PortProjects/SPHereSurvey.html#results-and-aspects-by-use-frequency",
    "title": "SPHere Survey Results",
    "section": "Results and aspects by use frequency",
    "text": "Results and aspects by use frequency\n\nSatisfaction\n\nLack of proper outlets is consistent across groups\nDecor satisfaction decreased as use frequency decreased\nFor those who use the lounge daily they are most dissatisfied with available technology and kitchen amenities with lighting, outlets, and private work space being close. This group however wasn’t as dissatisfied with furniture\n\n\n\nPriorities\n\nImportance of improving available technology is lower however in those who visit between 2-4 times a month it is their second highest priority. For those who included technology all but one had it as their highest.\nLighting is a consistent priority across groups; in those that visit less then once a month is their highest importance by a considerable margin. Shows possible reason for avoid the lounge.\nPriorities for those who use the lounge daily are furniture, collaborative space, and kitchen."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "",
    "text": "The 1995 Guatemalan Survey of Family Health (EGSF) collected information regarding health of children under the age of five and women during pregnancy and childbirth from 60 communities within 4 departments in Guatemala. The purpose of this study was to assess how the community level factors such as insurance access, transportation access, birth location, and health beliefs influence maternal and child health outcomes. The source of correlation was the community, as women in each community likely had shared experiences or beliefs due to their common environment. We fit two generalized linear mixed models with random intercepts to predict the odds of child mortality and odds of cesarean section for women from the same community. We hypothesized that the odds of C-section and child mortality would be lower in women who gave birth at home, had health insurance, and believed they shouldn’t see trained providers if bleeding during pregnancy. We found that these covariates did not predict child mortality. We found that mothers who had access to insurance and mothers who gave birth at a hospital had higher odds of having a C-section. This information can be used to help inform health policies and initiatives that seek to improve the health of Guatemalan women."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#abstract",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#abstract",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "",
    "text": "The 1995 Guatemalan Survey of Family Health (EGSF) collected information regarding health of children under the age of five and women during pregnancy and childbirth from 60 communities within 4 departments in Guatemala. The purpose of this study was to assess how the community level factors such as insurance access, transportation access, birth location, and health beliefs influence maternal and child health outcomes. The source of correlation was the community, as women in each community likely had shared experiences or beliefs due to their common environment. We fit two generalized linear mixed models with random intercepts to predict the odds of child mortality and odds of cesarean section for women from the same community. We hypothesized that the odds of C-section and child mortality would be lower in women who gave birth at home, had health insurance, and believed they shouldn’t see trained providers if bleeding during pregnancy. We found that these covariates did not predict child mortality. We found that mothers who had access to insurance and mothers who gave birth at a hospital had higher odds of having a C-section. This information can be used to help inform health policies and initiatives that seek to improve the health of Guatemalan women."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#introduction",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#introduction",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "Introduction",
    "text": "Introduction\nThe 1995 Guatemalan Survey of Family Health (EGSF) collected the health of children under the age of five and women during pregnancy and childbirth from 60 communities within 4 departments in rural Guatemala to understand a wide range of social, cultural, economic, and environmental conditions affecting maternal and child health1. Historically, few Guatemalans are able to access comprehensive healthcare, especially in rural areas. Public hospitals and clinics are highly underfunded and often lack basic medicine and equipment, since the government allocates minimal spending to healthcare. In some rural villages, there is no doctor or nurse, only a Non-Governmental Organization (NGO)-trained health worker who can provide very basic health services2.\nA US study found that infants born to mothers with private insurance had a significantly lower infant mortality rate (IMR), had significantly lower postneonatal mortality, low birth weight, vaginal breech delivery, preterm birth, and higher probability of prenatal care, compared with infants born to mothers with Medicaid3. Another study that estimated IMR between 2014 and 2016 using vital registration for 286 Latin American cities from eight countries found that mass transit availability (defined as availability of bus rapid transit and subway) was associated with 6.6% lower IMR4.\n\nOutcomes and Research Questions\nThis analysis investigates how community-related factors influence maternal and child health outcomes in rural Guatemala. This information can be used to help inform health policies and initiatives that seek to improve the health of Guatemalan women. The primary outcome of interest in this study is odds of child mortality and the secondary outcome is odds of birth delivery method (vaginal versus cesarean section). Therefore, our primary research question is as follows: How do the community-related factors of type of birth location, access to health insurance, access to emergency transportation, and mother’s beliefs regarding pregnancy health affect the odds that a woman from a given community will experience child mortality? The secondary research question investigates the same relationship between these factors on the outcome of delivery method."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#methods",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#methods",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "Methods",
    "text": "Methods\nThe study uses a stratified clustered sample design. Surveys were administered once per household in 4,782 households and to key local informants (e.g. healthcare providers) from 15 communities with fewer than 10,000 inhabitants in 4 departments of Guatemala. This analysis will account for correlation at the level of communities nested in departments by utilizing generalized linear mixed models. After initially joining the survey responses together, we had 3,226 responses. We then excluded 1,238 entries lacking consistent data, and removed survey entries not related to a woman’s first child, for a total of 1,988 responses. Some women had multiple children, but we wanted to focus on the first child to avoid multiple sources of clustering, especially as the risk of cesarean increases with a previous history of cesareans5. The final step was to exclude any individuals with missing data in the predictors of interest, for a total sample size of 1,897. These 1,897 women are from 60 communities. Each community is a cluster. There are anywhere from 15 to 49 women in each community, with the mean at 31.62 and the median at 31.5. Correlation arises due to shared individual and environmental characteristics that affect pregnancy and births, as a result of close proximity between women per cluster. For example, access to healthcare, socioeconomic status, and cultural attitudes towards seeing doctors or using birth control are expected to be similar in each area.\n\nVariables of Interest\nAll predictor variables were obtained through individual interviews with the women in the study. The primary outcome referred to as child mortality in this specific analysis is a yes/no response to the question “Is child still alive at the time of this interview?” The secondary outcome of the delivery method is a binary variable indicating either a vaginal or cesarean delivery. This study only looked at birth outcomes of the first child the mother had. Access to health insurance is a binary variable with the response options yes/no for if the mother/family has access to insurance through IGSS (the Guatemalan Social Security Institute) or another medical insurance. Transportation is a binary variable indicating if the family has access to some form of emergency transportation. Birthing location for most recent birth is a categorical variable collapsed from the original study response options to the following three categories: birth occurred at a home, a friend’s home, or a midwife’s home; birth occurred at a hospital, private clinic, health center/post, or with a nurse; or birth occurred an unspecified/other location. Health belief is a categorical variable for the woman’s answers to the question, “If she should see a provider for vaginal bleeding during pregnancy, and if so, what type of provider should she see?” The response options from the original study were collapsed into the following categories: should not ask anyone, asks only a medical provider, or asks either a traditional provider or both types of providers. Mother’s age is a continuous variable that measures the age of the mother at her last birthday before the survey was collected.\n\n\nInclusion and exclusion criteria\nA total of 3226 mothers were initially included for study consideration. 1238 of these were excluded for lack of consistent data, or because they described a child that was not the woman’s firstborn. 1988 entries remained. Responses were further excluded if data was missing related to emergency transportation, birth delivery method, and health beliefs. Finally, 1897 entries remained for analysis. The data flowchart is also presented (Appendix A).\n\n\nApproach to missing data\nVariables that took on values which were not included in the codebook were recoded as missing. Because of the low rates of missingness there were no special implications. To avoid excessive missingness, we decided to assume that women who gave birth to multiple children did so in the same place, which is completely reasonable due to the rural nature of the study and the fact that there were few health centers. This is also why children who were not the firstborn were excluded.\n\n\nExploratory data analysis\nDescriptive statistics were calculated looking at the overall sample of interest in this analysis as well as stratified by frequency of child mortality at time of interview and delivery method of first birth. This included the frequencies for each level of the predictor variables. All other covariates, including insurance access, access to emergency transportation, birth location, health beliefs, and mother’s age at the time of the interview, plus department identifier were displayed in each table with respective summary statistics. For interpretability of the descriptive statistics, numeric entries in the original dataset were recoded to corresponding categorical values according to the codebook, and combo entries were separated into multiple dummy variables. For geographic identifiers, more subdivided levels than departments such as municipalities were not displayed but accounted for in the following statistical analysis. Besides, information regarding the balances of women across clusters/communities and prevalence of missing data were examined using the original data. Child mortality and C-sections by community were explored in a bar plot (Appendix B).\n\n\nFitted Models\nTo account for the fact that these women are clustered in communities, we utilized generalized linear mixed models (GLMM) with random intercepts to account for the correlation within the clusters. We fit two binomial GLMMs with logit links to answer our questions. We used the “lme4” package in R 4.4.1 to fit the models, the “esticon” function in the “doBy” package to estimate 95% confidence intervals, the “anova” function in “stats” package to perform likelihood ratio tests (LRT), and “Anova” function in the “car” package to obtain Type III tests results for categorical variables with more than two levels. A p-value of &lt; 0.05 was considered significant. The primary model we fit investigated the possible effects of health insurance, transportation, birth location, health belief, and an interaction between location and transportation on the odds of child mortality. The interaction term was included to explore if the effect of birth location on child mortality depended on mothers’ emergency transportation access. Those with emergency transit access might be more likely to give birth in a hospital for an emergency, and may be more likely to have better child mortality outcomes than someone who gives birth in a hospital without emergency transit access in an emergency, thus taking a long time to get there, and modifying any effect giving birth in a hospital might have on the child mortality outcome. The secondary model investigated the effect of these predictors on the log odds of having a cesarean delivery. Following both of these analyses, we refitted these models after removing the interaction term between birth location and transportation to see if that changed the results compared to the original model."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#results",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#results",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "Results",
    "text": "Results\n\nDescriptive Data\nOf those who experienced child mortality, 15.9% of mothers reported having emergency transportation, whereas 84.1% of mothers did not. The mean age of mothers who experienced child mortality was 27.75 years old. 93.6% of mothers who experienced child mortality and reported their delivery method had a vaginal delivery, whereas 6.4% of women had a C-section. Of mothers with living children, most delivered at someone’s home (84.2%), followed by hospital/clinic deliveries (15.3%) and other locations (0.5%). Mothers with deceased children demonstrated a similar trend - 83.6% gave birth at home, 15.5% delivered at a hospital/clinic, and 0.9% reported “other.” For the health beliefs of mothers of deceased children, 92.3% said they would only see a medical provider, 5.5% would see a traditional provider or both providers, and 2.3% would not see anyone. Similarly, 91.7% of mothers with living children would only see a medical provider, 5% would see a traditional provider or both providers, and 3.3% would not see anyone. Of the mothers with deceased children, 90.5% reported having no insurance, compared to 86.6% of mothers with living children.\nWomen with health insurance more frequently had cesarean deliveries (28.6%) compared to women without health insurance (12.0%). Women with emergency transportation more frequently had cesareans (34.3%) compared to those without (18.8%). For women who had a cesarean as their first birth, the most common delivery location for their most recent child was hospital/clinic (67.7%), while the most common location for those whose first birth was vaginal was at someone’s home (87.3%). The trends for health belief by cesarean deliveries did not differ much by those described above for child mortality. Among women with vaginal deliveries, 206 (11.5%) had experienced child mortality while the remaining 1586 (88.5%) did not. Among women with cesarean deliveries, 14 (13.3% had experienced child mortality while the remaining 91 (86.7%) had not.\n\n\nModel Results\n\nPrimary\nWe concluded that health insurance, access to emergency transportation, birth location, health belief, and the effect of access to emergency transportation on birth location do not predict the odds of child mortality in a given community as no predictors were significant in the model (Figure 1). The random intercept (bi) represents the between-community variation. Compared to a woman from a given community who doesn’t have health insurance, the odds of child mortality for a woman from that community who does have health insurance are 33.3% lower (95% CI: 59.2% lower - 8.9% higher, p = 0.106), given that the other covariates are the same. Compared to a woman from a given community who doesn’t have emergency transportation, the odds of child mortality for a woman that does have access to emergency transportation from that community are 31.4% lower (95% CI: 57.3% lower to 10.3% higher, p = 0.12), given that the other covariates are the same. In a given community, women who gave birth at a hospital, clinic, or health post have 7% higher odds (95% CI: 34.5% lower to 74.9% higher, p = 0.786) of child mortality than women who gave birth at home when all other covariates were the same . In a given community, women who gave birth at an “other” location had 60.7% higher odds (95% CI: 82.9% lower to 1,388.4% higher, p = 0.676) of child mortality than women who gave birth at home when all other covariates were the same. In a given community, a woman who believed she should see a traditional provider when bleeding during pregnancy had 0.5% higher odds of child mortality (95% CI: 46.9% lower to 90% higher, p = 0.989) than a woman who believed she should see a trained provider when bleeding during pregnancy, when all other covariates were constant. In a given community, a woman who believed she should not see someone when bleeding during pregnancy had 34.4% lower odds of child mortality (95% CI: 74.3% lower to 67.2% higher, p = 0.377) than a woman who believed she should see a trained provider when bleeding during pregnancy when all other covariates were constant.\nIn our model, we posited that the effect of birth location on child mortality depended on mothers’ emergency transportation access, but the p-values of our interaction terms between emergency transportation and birth location were high and resulted in wide CIs that spanned the null hypothesis.\n\n\nSecondary\nWe fit a binomial GLMM with a random intercept and logit link . We found that mothers who gave birth at a hospital had 1,124.5% higher odds [CI: 618.7% to 1,986.3% higher odds, p &lt; .001] of having a C-section at first birth than mothers who gave birth at home, given they had the same values for the other covariates. Mothers who had access to insurance had 76.4% higher odds [CI: 6.2% to 192.9% higher, p &lt; .05] of having a C-section at first birth than mothers without access to health insurance, given they had the same values for the other covariates. A mother’s access to emergency transportation and health belief did not predict odds of c-section. A mother’s access to emergency transportation did not affect her birth location (Figure 2).\n\n\nSensitivity Analysis\nTo perform a sensitivity analysis with our primary model, we added the additional predictor of mother’s age at her last birthday (centered at the mean) (Appendix C). We expected maternal age to affect child mortality and delivery methods, such that older and younger women may have been more likely to undergo cesarean delivery or give birth to children with poor survival outcomes5. Additionally, we anticipated that maternal age may act in part as a precision variable for child mortality, as the odds of the woman’s first child being dead increases over time as the exposure to any life-threatening situations is cumulative. We found that for women in an average community, with every additional year of the mother’s age, the odds of the most recently born child being deceased at the time of interview increased by 5% (95% CI: 1.9% increase to 8.2% increase; p = .001). This was the only statistically significant predictor in the primary model. When we added the additional predictor of age to our secondary model, we found that age did not provide additional explanatory value. Adjusting for age did not have a large impact on the covariates of either model.\nFor the primary model with interaction, the likelihood ratio test against the model adjusted for mother’s age in addition showed that the later offered a better explanatory power (p = .001), while the same test conducted on the secondary model did not show any difference in the goodness of fit with or without the age term (p = .798). Similar results were obtained for all alternate models of the secondary outcome, as none resulted in changes to the significance of insurance and location predictors. (Appendix D)."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#discussion",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#discussion",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "Discussion",
    "text": "Discussion\nNo community-level predictors were significantly associated with child mortality. Maternal age was in fact significant in the models it was added to, demonstrating that our understanding of its use as a precision variable was reasonable. However, its inclusion did not result in any significant estimates for any other terms. Women who gave birth in a hospital/clinic for their most recent birth had 12.245 higher odds of having a c-section for their first pregnancy. This is understandable as the risk of c-section increases if a woman has previously had a c-section. Access to insurance is associated with 76% higher odds of cesarean delivery. This makes sense, as women without insurance may be less likely to go to a hospital/clinic for their birth and instead have birth at a home, where c-sections are not an available option. In all models, the residual error was higher than the error of the fixed community effect; the SE of the community effect was very low. This indicates that within-community variability is higher than between-community variability - the data are less correlated than we thought."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#limitations",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#limitations",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "Limitations",
    "text": "Limitations\nThe relative low number of C-sections contributed to the high variability of our model (in 12 of the 60 communities, no woman had a C-section, and for the 48 communities where at least one woman had a C-section, the number was low (Appendix B). The low number of women who responded that bleeding mothers should not see any type of provider (n = 60) could explain the extremely wide CIs in our model (Figures 2 & 3). The overall low number of insured families (n = 245) could explain the high variability of the insurance predictor in our models (Table 1).\nThe study utilized mostly interviews, so most of the individual-level birth outcomes were obtained from mothers directly, introducing the possibility of survivor bias. By not including the rates of cesareans or child mortality for mothers who did not survive childbirth, there may be additional nuance regarding health predictors that this study cannot address. The original study’s utilization of community key informant interviews does a good job of collecting health information that is not at the level of surviving individuals, but combining the analysis of this dataset with vital statistics or hospital records, if available, may provide a more complete picture of community-level maternal health. In all models, the residual error was higher than the error of the fixed community effect; the SE of the community effect was very low. This indicates that within-community variability is higher than between-community variability - the data are less correlated than we thought. It may be appropriate to assume that the survey responses are independent rather than correlated due to the community clustering, and thus fit a logistic GLM instead.\nThe available data on child age at time of death was not collected consistently so it could not be used to calculate child mortality before the age of one. Instead, our “child mortality” variable was whether the woman’s first born child was alive at the time of interview. The length of time between the child’s birth and interview data could not be calculated. This led us to explore maternal age as a precision variable instead. However, more clear relationships may be understood if mortality before age one is able to be modeled. Additionally, this analysis had to assume that women’s birth location for their most recent birth is similar to the location of their first birth as there was no question asked about the location for their most recent birth. Though this was not an unreasonable assumption, causal relationships could have been clearer if the birth location variable was also present for the woman’s most recent delivery."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#implicationsfuture-directions",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#implicationsfuture-directions",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "Implications/Future Directions",
    "text": "Implications/Future Directions\nOur results clearly demonstrated that access to insurance is a predictor of cesarean delivery. This may indicate that women with insurance may be more likely to go to a hospital or health center with either surgical capabilities or the infrastructure to transport patients requiring a cesarean section to a higher level of care. However, this does not mean that only women with insurance are medically indicated to have c-sections. It may be interesting to see how insurance access interacts with health-related predictors of cesarean deliveries, such as fetal distress or positioning. It is unlikely that only women with insurance require c-sections, so better understanding the interaction between needing a c-section and insurance access not only on the outcome of cesarean delivery but other key indicators of maternal mortality, infant mortality, or severe complications such as hemorrhage or eclampsia may inform public health initiatives to improve insurance and healthcare access in rural Guatemala."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#references",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#references",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "References",
    "text": "References\nPebley, Anne R., and Goldman, Noreen. Guatemalan Survey of Family Health (EGSF), 1995. Inter-university Consortium for Political and Social Research [distributor], 2006-01-12.\nCronin J. Healthcare System in Guatemala. International Citizens Insurance.\nJohnson DL, Carlo WA, Rahman AKMF, et al. Health Insurance and Differences in Infant Mortality Rates in the US. JAMA Netw Open. 2023;6(10):e2337690.\nOrtigoza, A. F., Tapia Granados, J. A., Miranda, J. J., Alazraqui, M., Higuera, D., Villamonte, G., Friche, A. A. L., Barrientos Gutierrez, T., & Diez Roux, A. V. (2021). Characterising variability and predictors of infant mortality in urban settings: findings from 286 Latin American cities. Journal of epidemiology and community health, 75(3), 264–270. .\nDe Souza HCC, Perdoná GSC, Marcolin AC, et al. Development of caesarean section prediction models: secondary analysis of a prospective cohort study in two sub-Saharan African countries. Reprod Health. 2019;16(1):165. doi:"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#appendix",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#appendix",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "Appendix",
    "text": "Appendix\n\nMain Figures and Tables"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#supplemental-appendix-a---data-exclusion-flowchart",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#supplemental-appendix-a---data-exclusion-flowchart",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "Supplemental Appendix A - Data Exclusion Flowchart",
    "text": "Supplemental Appendix A - Data Exclusion Flowchart"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#supplemental-appendix-b---community-clusters",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#supplemental-appendix-b---community-clusters",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "Supplemental Appendix B - Community Clusters",
    "text": "Supplemental Appendix B - Community Clusters"
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#supplemental-appendix-c---primary-model-results",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#supplemental-appendix-c---primary-model-results",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "Supplemental Appendix C - Primary Model Results",
    "text": "Supplemental Appendix C - Primary Model Results\n\nTable 1.\nResults of the primary model utilizing GLMMs to assess the relationship between community level predictors and the odds of child mortality. Significance of multi-level categorical predictors was calculated using Type III tests.\n\n\n\nTable 2.\nResults of the primary model utilizing GLMMS to assess the relationship between community level predictors and the odds of child mortality, with the interaction term between transportation and location removed. Significance of multi-level categorical predictors was calculated using Type III tests.\n\n\n\nTable 3.\nResults of the primary model utilizing GLMMs to assess the relationship between community level predictors and the odds of child mortality. Maternal age was added as a covariate and the interaction term between transportation and location was removed. Significance of multi-level categorical predictors was calculated using Type III tests.\n\n\n\nTable 4.\nResults of the primary model utilizing GLMMs to assess the relationship between community level predictors and the odds of child mortality, with maternal age added as a covariate. Significance of multi-level categorical predictors was calculated using Type III tests."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#supplemental-appendix-d---secondary-model-results",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#supplemental-appendix-d---secondary-model-results",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "Supplemental Appendix D - Secondary Model Results",
    "text": "Supplemental Appendix D - Secondary Model Results\n\nTable 5.\nResults of the secondary model utilizing generalized linear mixed models to assess the relationship between community level predictors and the odds of c-section delivery. Significance of multi-level categorical predictors was calculated using Type III tests.\n\n\n\nTable 6. Results of the secondary model utilizing generalized linear mixed models to assess the relationship between community level predictors and the odds of c-section delivery, with the interaction term between transportation and location removed. Significance of multi-level categorical predictors was calculated using Type III tests.\n\n\n\nTable 7.\nResults of the secondary model utilizing generalized linear mixed models to assess the relationship between community level predictors and the odds of c-section delivery. Maternal age was added as a covariate and the interaction term between transportation and location was removed. Significance of multi-level categorical predictors was calculated using Type III tests.\n\n\n\nTable 8.\nResults of the secondary model utilizing generalized linear mixed models to assess the relationship between community level predictors and the odds of c-section delivery, with maternal age added as a covariate. Significance of multi-level categorical predictors was calculated using Type III tests."
  },
  {
    "objectID": "Sections/Portfolio/PortProjects/Child_Mortality.html#supplemental-appendix-e---conflicts-of-interest-and-acknowledgements",
    "href": "Sections/Portfolio/PortProjects/Child_Mortality.html#supplemental-appendix-e---conflicts-of-interest-and-acknowledgements",
    "title": "Predicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models",
    "section": "Supplemental Appendix E - Conflicts of Interest and Acknowledgements",
    "text": "Supplemental Appendix E - Conflicts of Interest and Acknowledgements\nThe authors declare no conflicts of interest. However, all authors benefited from Lulu the sassy cat."
  },
  {
    "objectID": "Sections/Portfolio/index.html",
    "href": "Sections/Portfolio/index.html",
    "title": "Selected Projects",
    "section": "",
    "text": "Biostat Reference Guide\n\n\nReference for biostatistics 1 and 2\n\n\n\n\n\n\n\n\nJonathan Barnes\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting Child Mortality and Cesarean Delivery Outcomes with Generalized Linear Mixed Models\n\n\nAnalysis of the 1995 Guatemalan Survey of Family Health (EGSF)\n\n\n\n\n\n\n\n\nDec 18, 2024\n\n\nJonathan Barnes, Tiffany Chang, Yiheng Liu, Elise Steichen, Sarah Vandenbergen\n\n\n\n\n\n\n\n\n\n\n\n\nMapping Misery\n\n\nPredicting America’s Procession of Pain, Panic, and Poor Days using GMM clustering of a correspondance analysis and elastic net regression\n\n\n\n\n\n\n\n\nDec 11, 2024\n\n\nJonathan Barnes\n\n\n\n\n\n\n\n\n\n\n\n\nSPHere Survey Results\n\n\nResults of the 2024 SPHere survey summarising what students would like to see improved and what should be prioritized\n\n\n\n\n\n\n\n\nApr 24, 2024\n\n\nJonathan Barnes, Maya Koffski, Caylin Crawford\n\n\n\n\n\n\n\n\n\n\n\n\nTech Desk Tools\n\n\nOverview of python application I created to aid productivity and reduce learning curve to working at the Tech Desk at the University of St. Thomas\n\n\n\n\n\n\n\n\nApr 18, 2023\n\n\nJonathan Barnes\n\n\n\n\n\n\nNo matching items"
  }
]